{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing import image\n",
    "import sklearn.model_selection\n",
    "from keras.utils.np_utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image_Name</th>\n",
       "      <th>Competency_Score</th>\n",
       "      <th>Trustworthy_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B321</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B410</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B58</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B86</td>\n",
       "      <td>3.5</td>\n",
       "      <td>7.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B268</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>B85</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>B888</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>B65</td>\n",
       "      <td>5.5</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>B622</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>B150</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.67</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Image_Name  Competency_Score  Trustworthy_Score\n",
       "0       B321               4.0               5.33\n",
       "1       B410               6.0               6.00\n",
       "2        B58               3.0               3.00\n",
       "3        B86               3.5               7.00\n",
       "4       B268               3.0               5.00\n",
       "5        B85               7.0               8.00\n",
       "6       B888               7.0              10.00\n",
       "7        B65               5.5               3.00\n",
       "8       B622               8.0               5.00\n",
       "9       B150               5.0               6.67"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= pd.read_csv('Train.csv')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib64/python3.6/site-packages/keras_preprocessing/image/utils.py:98: UserWarning: grayscale is deprecated. Please use color_mode = \"grayscale\"\n",
      "  warnings.warn('grayscale is deprecated. Please use '\n"
     ]
    }
   ],
   "source": [
    "All_img = []\n",
    "for i in df['Image_Name']:\n",
    "    img= image.load_img('TrainPictures/'+ i + '.jpg' , target_size=(128,80,1),grayscale=True)\n",
    "    img= image.img_to_array(img)\n",
    "    img=img/255\n",
    "    All_img.append(img)\n",
    "X=np.array(All_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y= df['Competency_Score'].values\n",
    "Y= keras.utils.np_utils.to_categorical(Y)\n",
    "train_x,valid_x, train_y, valid_y = sklearn.model_selection.train_test_split(X,Y, random_state= 40, test_size= 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape :  (640, 128, 80, 1) (640, 11)\n",
      "Testing data shape :  (160, 128, 80, 1) (160, 11)\n"
     ]
    }
   ],
   "source": [
    "print('Training data shape : ', train_x.shape, train_y.shape)\n",
    "print('Testing data shape : ', valid_x.shape, valid_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing test data for final evaluation\n",
    "df1= pd.read_csv('TestSamples.csv')\n",
    "# df1.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib64/python3.6/site-packages/keras_preprocessing/image/utils.py:98: UserWarning: grayscale is deprecated. Please use color_mode = \"grayscale\"\n",
      "  warnings.warn('grayscale is deprecated. Please use '\n"
     ]
    }
   ],
   "source": [
    "Test_img = []\n",
    "for i in df1['Image_Name']:\n",
    "    img= image.load_img('TestPictures/'+ i + '.jpg' , target_size=(128,80,1),grayscale=True)\n",
    "    img= image.img_to_array(img)\n",
    "    img=img/255\n",
    "    Test_img.append(img)\n",
    "test_X=np.array(Test_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks(CNN) model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential,Input,Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from tensorflow.keras import backend\n",
    "from tensorflow.python.keras import backend\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "epochs = 20\n",
    "num_classes = 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),activation='linear',input_shape=(128,80,1),padding='same'))\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "#model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(MaxPooling2D((2, 2),padding='same'))\n",
    "model.add(Dropout(0.20))\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),activation='linear',input_shape=(128,80,1),padding='same'))\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "#model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(MaxPooling2D((2, 2),padding='same'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='linear',padding='same'))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "# model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
    "model.add(Dropout(0.20))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='linear',padding='same'))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "#model.add(LeakyReLU(alpha=0.1))                  \n",
    "model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
    "model.add(Dropout(0.15))\n",
    "\n",
    "model.add(Conv2D(128, kernel_size=(3, 3),activation='linear',input_shape=(128,80,1),padding='same'))\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "#model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(MaxPooling2D((2, 2),padding='same'))\n",
    "model.add(Dropout(0.15))\n",
    "\n",
    "model.add(Conv2D(256, (3, 3), activation='linear',padding='same'))\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "#model.add(LeakyReLU(alpha=0.1))                  \n",
    "model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
    "model.add(Dropout(0.15))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='linear'))\n",
    "model.add(layers.Dense(11, activation='relu'))\n",
    "#model.add(LeakyReLU(alpha=0.1))                  \n",
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adam(),metrics=['accuracy'])\n",
    "from keras import metrics\n",
    "# model.compile(loss='mse', optimizer='adam', metrics=[metrics.mean_squared_error])\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 640 samples, validate on 160 samples\n",
      "Epoch 1/20\n",
      "640/640 [==============================] - 5s 8ms/step - loss: 0.0760 - acc: 0.2516 - val_loss: 0.0794 - val_acc: 0.1562\n",
      "Epoch 2/20\n",
      "640/640 [==============================] - 5s 8ms/step - loss: 0.0762 - acc: 0.2578 - val_loss: 0.0800 - val_acc: 0.1437\n",
      "Epoch 3/20\n",
      "640/640 [==============================] - 5s 8ms/step - loss: 0.0761 - acc: 0.2375 - val_loss: 0.0790 - val_acc: 0.2188\n",
      "Epoch 4/20\n",
      "640/640 [==============================] - 5s 8ms/step - loss: 0.0746 - acc: 0.2719 - val_loss: 0.0806 - val_acc: 0.1625\n",
      "Epoch 5/20\n",
      "640/640 [==============================] - 5s 8ms/step - loss: 0.0738 - acc: 0.2891 - val_loss: 0.0792 - val_acc: 0.1875\n",
      "Epoch 6/20\n",
      "640/640 [==============================] - 5s 8ms/step - loss: 0.0734 - acc: 0.2938 - val_loss: 0.0805 - val_acc: 0.1938\n",
      "Epoch 7/20\n",
      "640/640 [==============================] - 5s 8ms/step - loss: 0.0725 - acc: 0.3250 - val_loss: 0.0828 - val_acc: 0.1500\n",
      "Epoch 8/20\n",
      "640/640 [==============================] - 5s 8ms/step - loss: 0.0731 - acc: 0.3047 - val_loss: 0.0834 - val_acc: 0.1500\n",
      "Epoch 9/20\n",
      "640/640 [==============================] - 5s 8ms/step - loss: 0.0728 - acc: 0.3188 - val_loss: 0.0842 - val_acc: 0.1125\n",
      "Epoch 10/20\n",
      "640/640 [==============================] - 5s 8ms/step - loss: 0.0726 - acc: 0.3094 - val_loss: 0.0804 - val_acc: 0.1688\n",
      "Epoch 11/20\n",
      "640/640 [==============================] - 5s 8ms/step - loss: 0.0721 - acc: 0.3203 - val_loss: 0.0822 - val_acc: 0.1812\n",
      "Epoch 12/20\n",
      "640/640 [==============================] - 5s 8ms/step - loss: 0.0694 - acc: 0.3578 - val_loss: 0.0861 - val_acc: 0.1250\n",
      "Epoch 13/20\n",
      "640/640 [==============================] - 5s 8ms/step - loss: 0.0704 - acc: 0.3484 - val_loss: 0.0844 - val_acc: 0.1562\n",
      "Epoch 14/20\n",
      "640/640 [==============================] - 5s 8ms/step - loss: 0.0679 - acc: 0.3813 - val_loss: 0.0882 - val_acc: 0.1812\n",
      "Epoch 15/20\n",
      "640/640 [==============================] - 5s 8ms/step - loss: 0.0680 - acc: 0.3641 - val_loss: 0.0831 - val_acc: 0.1500\n",
      "Epoch 16/20\n",
      "640/640 [==============================] - 5s 8ms/step - loss: 0.0665 - acc: 0.3906 - val_loss: 0.0835 - val_acc: 0.1500\n",
      "Epoch 17/20\n",
      "640/640 [==============================] - 5s 8ms/step - loss: 0.0640 - acc: 0.4156 - val_loss: 0.0918 - val_acc: 0.1437\n",
      "Epoch 18/20\n",
      "640/640 [==============================] - 5s 8ms/step - loss: 0.0645 - acc: 0.4109 - val_loss: 0.0897 - val_acc: 0.1750\n",
      "Epoch 19/20\n",
      "640/640 [==============================] - 5s 8ms/step - loss: 0.0639 - acc: 0.4438 - val_loss: 0.0851 - val_acc: 0.1562\n",
      "Epoch 20/20\n",
      "640/640 [==============================] - 5s 8ms/step - loss: 0.0627 - acc: 0.4469 - val_loss: 0.0901 - val_acc: 0.1625\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7efdc75aee10>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_x,train_y, batch_size=batch_size,epochs=20, validation_data=(valid_x,valid_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions_Trustworthy Score [5 5 5 5 5 5 4 5 5 3 4 5 5 5 5 8 6 7 7 5 6 6 5 5 6 5 5 7 7 7 4 7 5 4 5 5 6\n",
      " 5 4 5 7 5 5 6 3 5 4 5 4 3 5 5 7 5 4 7 5 4 5 6 5 5 6 6 6 8 6 7 4 5 6 5 5 4\n",
      " 3 8 5 5 6 3 6 4 6 8 5 5 4 6 5 6 7 7 5 5 5 5 6 4 4 6 5 5 5 4 5 5 8 8 6 5 5\n",
      " 6 5 5 5 4 8 6 6 6 8 6 7 5 6 7 8 6 6 4 7 7 7]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # train.history\n",
    "print('predictions_Trustworthy Score', model.predict_classes(test_X))\n",
    "type(model.predict_classes(test_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Trust= model.predict_classes(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#doploying model 2 for Competency_Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y= df['Competency_Score'].values\n",
    "Y= keras.utils.np_utils.to_categorical(Y)\n",
    "train_x,valid_x, train_y, valid_y = sklearn.model_selection.train_test_split(X,Y, random_state= 40, test_size= 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = tf.keras.Sequential()\n",
    "model_2.add(Conv2D(32, kernel_size=(3, 3),activation='linear',input_shape=(128,80,1),padding='same'))\n",
    "model_2.add(layers.Dense(32, activation='relu'))\n",
    "#model.add(LeakyReLU(alpha=0.1))\n",
    "model_2.add(MaxPooling2D((2, 2),padding='same'))\n",
    "model_2.add(Dropout(0.20))\n",
    "\n",
    "model_2.add(Conv2D(32, kernel_size=(3, 3),activation='linear',input_shape=(128,80,1),padding='same'))\n",
    "model_2.add(layers.Dense(32, activation='relu'))\n",
    "#model.add(LeakyReLU(alpha=0.1))\n",
    "model_2.add(MaxPooling2D((2, 2),padding='same'))\n",
    "model_2.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "model_2.add(Conv2D(64, (3, 3), activation='linear',padding='same'))\n",
    "model_2.add(layers.Dense(64, activation='relu'))\n",
    "# model.add(LeakyReLU(alpha=0.1))\n",
    "model_2.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
    "model_2.add(Dropout(0.20))\n",
    "\n",
    "model_2.add(Conv2D(64, (3, 3), activation='linear',padding='same'))\n",
    "model_2.add(layers.Dense(64, activation='relu'))\n",
    "#model.add(LeakyReLU(alpha=0.1))                  \n",
    "model_2.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
    "model_2.add(Dropout(0.15))\n",
    "\n",
    "model_2.add(Conv2D(128, kernel_size=(3, 3),activation='linear',input_shape=(128,80,1),padding='same'))\n",
    "model_2.add(layers.Dense(128, activation='relu'))\n",
    "#model.add(LeakyReLU(alpha=0.1))\n",
    "model_2.add(MaxPooling2D((2, 2),padding='same'))\n",
    "model_2.add(Dropout(0.15))\n",
    "\n",
    "# model.add(Conv2D(256, (3, 3), activation='linear',padding='same'))\n",
    "# model.add(layers.Dense(128, activation='relu'))\n",
    "# #model.add(LeakyReLU(alpha=0.1))                  \n",
    "# model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
    "# model.add(Dropout(0.15))\n",
    "\n",
    "model_2.add(Flatten())\n",
    "model_2.add(Dense(128, activation='linear'))\n",
    "model_2.add(layers.Dense(11, activation='relu'))\n",
    "#model.add(LeakyReLU(alpha=0.1))                  \n",
    "model_2.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#similarly for Competency_Score we get these results\n",
    "comp= model_2.predict_classes(test_X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "final=pd.DataFrame(data=[comp, Trust]).T\n",
    "final.columns = ['Competency_Score','Trustworthy_Score']\n",
    "final[\"Competency_Score\"] = final[\"Competency_Score\"].astype(float)\n",
    "final[\"Trustworthy_Score\"] = final[\"Trustworthy_Score\"].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output results to csv\n",
    "final.to_csv('B.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
